{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49414bce",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "d135c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation libraries\n",
    "import pandas as pd # Dataframes\n",
    "\n",
    "# Statistical libraries\n",
    "from sklearn.model_selection import train_test_split # Split dataset for validation\n",
    "from sklearn.model_selection import cross_val_score # Cross validation for models\n",
    "from sklearn.model_selection import GridSearchCV # Hyperparameter fine-tuning\n",
    "\n",
    "# Modeling libraries\n",
    "from sklearn.linear_model import LinearRegression, GammaRegressor, BayesianRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Warnings\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11845ddb",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "7e5097b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/clean_data_2.csv')\\\n",
    "           .drop(columns = ['Order_ID'])\\\n",
    "           .dropna()\n",
    "\n",
    "target_col = 'Delivery_Time_min'\n",
    "X = df.drop(columns = target_col)\n",
    "y = df[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46ef94e",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "73613aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model_name:str, X:pd.DataFrame, y:pd.Series, \n",
    "               models:dict, test_size:float = 0.3, random_state:int = 42, \n",
    "               verbose:bool = False) -> tuple[str,float,float,float]:\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size = test_size, \n",
    "        random_state = random_state\n",
    "    )  \n",
    "\n",
    "    try:\n",
    "        # Train model      \n",
    "        model = models[model_name]\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate\n",
    "        score_cv = cross_val_score(model, X_train, y_train, cv=5)\n",
    "        score_test = model.score(X_test, y_test)\n",
    "        if verbose:\n",
    "            print(f'{model_name} \\n'\\\n",
    "                f'mean cross-validation score: {score_cv.mean():0.4f} '\\\n",
    "                f'with a standard deviation of {score_cv.std():0.4f}\\n'\\\n",
    "                f'test score: {score_test:0.4f}\\n'\\\n",
    "                '-----')\n",
    "        \n",
    "        return (model_name, score_cv.mean(), score_cv.std(), score_test)\n",
    "    \n",
    "    except:\n",
    "        return (model_name, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "5c30d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Linear Regression': LinearRegression()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "41f9b2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression \n",
      "mean cross-validation score: 0.7517 with a standard deviation of 0.0366\n",
      "test score: 0.8351\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Linear Regression',\n",
       " 0.7516632570579345,\n",
       " 0.0365981173095549,\n",
       " 0.8351348286803177)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model('Linear Regression', X, y, models, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebed19e",
   "metadata": {},
   "source": [
    "# Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7f04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dataset(path:str, target_col:str, models:dict[str,object], \n",
    "                     drop_cols:list[str] = [], dropna:bool = True) -> pd.DataFrame:\n",
    "\n",
    "    df = pd.read_csv(path)\\\n",
    "           .drop(columns = drop_cols)\n",
    "    \n",
    "    if dropna:\n",
    "        df = df.dropna()\n",
    "\n",
    "    X = df.drop(columns = target_col)\n",
    "    y = df[target_col]\n",
    "\n",
    "    model_scores = []\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        for m in models.keys():\n",
    "            model_scores.append(eval_model(m, X, y, models, verbose = False))\n",
    "\n",
    "    df_scores = pd.DataFrame(\n",
    "        model_scores,\n",
    "        columns = ['model_name','score_cv_mean','score_cv_std','score_test']\n",
    "    ).sort_values(\n",
    "        by = 'score_test',\n",
    "        ascending = False\n",
    "    )\n",
    "\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "20fe17a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_models(root_file_name:str, target_col:str, \n",
    "                    models: dict[str,object],drop_cols:list[str] = []) -> pd.DataFrame:\n",
    "\n",
    "    models_df = pd.DataFrame(columns = ['dataset', 'model_name','score_cv_mean','score_cv_std','score_test'])\n",
    "\n",
    "    for i in range(2,5):\n",
    "\n",
    "        file_name = f'{root_file_name}{i}'\n",
    "\n",
    "        temp_df = eval_dataset(\n",
    "            path = f'data/{file_name}.csv', \n",
    "            target_col = target_col, \n",
    "            models = models,\n",
    "            drop_cols = drop_cols\n",
    "        )\n",
    "\n",
    "        temp_df['dataset'] = file_name\n",
    "\n",
    "        models_df = pd.concat([models_df, temp_df])\n",
    "    \n",
    "    return models_df.sort_values(by = 'score_test', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea501b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    # Linear models\n",
    "    'Gamma Regression': GammaRegressor(),\n",
    "\n",
    "    # Bayesian\n",
    "    'Bayesian Ridge': BayesianRidge(),\n",
    "    \n",
    "    # Decision Trees and Ensembles\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'LightGBM': LGBMRegressor(),\n",
    "    \n",
    "    # Support Vector Machines\n",
    "    'Linear Support Vector Regression': LinearSVR(),\n",
    "    \n",
    "    # Instance Based Learning\n",
    "    'KNeighbors': KNeighborsRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "102aab28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saldana.e.3\\AppData\\Local\\Temp\\ipykernel_27164\\1371637755.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  models_df = pd.concat([models_df, temp_df])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model_name</th>\n",
       "      <th>score_cv_mean</th>\n",
       "      <th>score_cv_std</th>\n",
       "      <th>score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>clean_data_2</td>\n",
       "      <td>Linear Support Vector Regression</td>\n",
       "      <td>0.749421</td>\n",
       "      <td>0.029543</td>\n",
       "      <td>0.837113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clean_data_3</td>\n",
       "      <td>Bayesian Ridge</td>\n",
       "      <td>0.751822</td>\n",
       "      <td>0.035869</td>\n",
       "      <td>0.835099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clean_data_4</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.724955</td>\n",
       "      <td>0.035503</td>\n",
       "      <td>0.770208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clean_data_4</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.693352</td>\n",
       "      <td>0.056056</td>\n",
       "      <td>0.768855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clean_data_4</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.717549</td>\n",
       "      <td>0.039740</td>\n",
       "      <td>0.761799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clean_data_2</td>\n",
       "      <td>Gamma Regression</td>\n",
       "      <td>0.723414</td>\n",
       "      <td>0.034846</td>\n",
       "      <td>0.759337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>clean_data_2</td>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.655945</td>\n",
       "      <td>0.061167</td>\n",
       "      <td>0.720834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clean_data_4</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.439434</td>\n",
       "      <td>0.095677</td>\n",
       "      <td>0.379672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset                        model_name  score_cv_mean  \\\n",
       "6  clean_data_2  Linear Support Vector Regression       0.749421   \n",
       "1  clean_data_3                    Bayesian Ridge       0.751822   \n",
       "2  clean_data_4                 Gradient Boosting       0.724955   \n",
       "3  clean_data_4                     Random Forest       0.693352   \n",
       "5  clean_data_4                          LightGBM       0.717549   \n",
       "0  clean_data_2                  Gamma Regression       0.723414   \n",
       "7  clean_data_2                        KNeighbors       0.655945   \n",
       "4  clean_data_4                     Decision Tree       0.439434   \n",
       "\n",
       "   score_cv_std  score_test  \n",
       "6      0.029543    0.837113  \n",
       "1      0.035869    0.835099  \n",
       "2      0.035503    0.770208  \n",
       "3      0.056056    0.768855  \n",
       "5      0.039740    0.761799  \n",
       "0      0.034846    0.759337  \n",
       "7      0.061167    0.720834  \n",
       "4      0.095677    0.379672  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_models(\n",
    "    root_file_name = 'clean_data_',\n",
    "    target_col = 'Delivery_Time_min',\n",
    "    models = models,\n",
    "    drop_cols = ['Order_ID']\n",
    ").drop_duplicates(subset = ['model_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f02d3",
   "metadata": {},
   "source": [
    "# Hyperparameter fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model(path:str, target_col: str, model, param_grid,\n",
    "               drop_cols:list[str] = [], dropna:bool = True) -> dict:\n",
    "    \n",
    "    df = pd.read_csv(path)\\\n",
    "           .drop(columns = drop_cols)\n",
    "    \n",
    "    if dropna:\n",
    "        df = df.dropna()\n",
    "\n",
    "    X = df.drop(columns = target_col)\n",
    "    y = df[target_col]\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size = 0.3, \n",
    "        random_state = 42\n",
    "    ) \n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        model,\n",
    "        param_grid,\n",
    "        cv = 5, scoring = 'r2'\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train,y_train)\n",
    "\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0fed12",
   "metadata": {},
   "source": [
    "## Linear Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c889a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'epsilon': 0.01, 'loss': 'squared_epsilon_insensitive', 'tol': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'tol': [0.000001, 0.00001, 0.0001, 0.001, 0.01],\n",
    "    'epsilon': [0, 0.01, 0.05, 0.1, 0.5],\n",
    "    'loss': ['epsilon_insensitive', 'squared_epsilon_insensitive']\n",
    "}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    best_params = finetune_model(\n",
    "        'data/clean_data_2.csv',\n",
    "        'Delivery_Time_min',\n",
    "        LinearSVR(),\n",
    "        param_grid,\n",
    "        drop_cols = ['Order_ID']\n",
    "    )\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac064884",
   "metadata": {},
   "source": [
    "## Bayesian Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c4d0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha_1': 0.001, 'alpha_2': 1e-07, 'lambda_1': 1e-07, 'lambda_2': 0.001}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'alpha_1': [1e-7, 1e-6, 1e-5, 1e-4, 1e-3],\n",
    "    'alpha_2': [1e-7, 1e-6, 1e-5, 1e-4, 1e-3],\n",
    "    'lambda_1': [1e-7, 1e-6, 1e-5, 1e-4, 1e-3],\n",
    "    'lambda_2': [1e-7, 1e-6, 1e-5, 1e-4, 1e-3]\n",
    "}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    best_params = finetune_model(\n",
    "        'data/clean_data_2.csv',\n",
    "        'Delivery_Time_min',\n",
    "        BayesianRidge(),\n",
    "        param_grid,\n",
    "        drop_cols = ['Order_ID']\n",
    "    )\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "59053aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Baseline Linear SVR': LinearSVR(),\n",
    "    'Fine-tuned Linear SVR': LinearSVR(\n",
    "        C = 0.1, epsilon = 0.01, tol = 1e-05,\n",
    "        loss = 'squared_epsilon_insensitive'),\n",
    "    \n",
    "    'Baseline Bayesian Ridge': BayesianRidge(),\n",
    "    'Fine-tuned Bayesian Ridge': BayesianRidge(\n",
    "        alpha_1 = 0.001, alpha_2 = 1e-07, \n",
    "        lambda_1 = 1e-07, lambda_2 = 0.001)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "febb7303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saldana.e.3\\AppData\\Local\\Temp\\ipykernel_27164\\1371637755.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  models_df = pd.concat([models_df, temp_df])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model_name</th>\n",
       "      <th>score_cv_mean</th>\n",
       "      <th>score_cv_std</th>\n",
       "      <th>score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clean_data_2</td>\n",
       "      <td>Baseline Linear SVR</td>\n",
       "      <td>0.749425</td>\n",
       "      <td>0.030659</td>\n",
       "      <td>0.837862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clean_data_2</td>\n",
       "      <td>Fine-tuned Linear SVR</td>\n",
       "      <td>0.751859</td>\n",
       "      <td>0.035624</td>\n",
       "      <td>0.835404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clean_data_3</td>\n",
       "      <td>Fine-tuned Bayesian Ridge</td>\n",
       "      <td>0.751822</td>\n",
       "      <td>0.035869</td>\n",
       "      <td>0.835099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clean_data_3</td>\n",
       "      <td>Baseline Bayesian Ridge</td>\n",
       "      <td>0.751822</td>\n",
       "      <td>0.035869</td>\n",
       "      <td>0.835099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset                 model_name  score_cv_mean  score_cv_std  \\\n",
       "0  clean_data_2        Baseline Linear SVR       0.749425      0.030659   \n",
       "1  clean_data_2      Fine-tuned Linear SVR       0.751859      0.035624   \n",
       "3  clean_data_3  Fine-tuned Bayesian Ridge       0.751822      0.035869   \n",
       "2  clean_data_3    Baseline Bayesian Ridge       0.751822      0.035869   \n",
       "\n",
       "   score_test  \n",
       "0    0.837862  \n",
       "1    0.835404  \n",
       "3    0.835099  \n",
       "2    0.835099  "
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_models(\n",
    "    root_file_name = 'clean_data_',\n",
    "    target_col = 'Delivery_Time_min',\n",
    "    models = models,\n",
    "    drop_cols = ['Order_ID']\n",
    ").drop_duplicates(subset = ['model_name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
